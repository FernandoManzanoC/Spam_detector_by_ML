{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos SVM sin aplicar tecnicas para el desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación en el conjunto de prueba:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       732\n",
      "        spam       0.96      0.97      0.97       267\n",
      "\n",
      "    accuracy                           0.98       999\n",
      "   macro avg       0.98      0.98      0.98       999\n",
      "weighted avg       0.98      0.98      0.98       999\n",
      "\n",
      "Matriz de Confusión en el conjunto de prueba:\n",
      "[[722  10]\n",
      " [  8 259]]\n",
      "Exactitud en el conjunto de prueba:\n",
      "0.9819819819819819\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Supongamos que df es tu DataFrame con las columnas 'text' y 'label_num'\n",
    "df = pd.read_csv('../data_en/spam_ham_dataset_modificado.csv')  # Asegúrate de cargar tus datos correctamente\n",
    "\n",
    "# Preparar datos\n",
    "X = df['text']\n",
    "y = df['label_num']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizar el texto\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar el modelo SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_test_pred = svm_model.predict(X_test_vec)\n",
    "\n",
    "# Reporte de Clasificación\n",
    "print(\"Reporte de Clasificación en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['ham', 'spam']))\n",
    "\n",
    "# Matriz de Confusión\n",
    "print(\"Matriz de Confusión en el conjunto de prueba:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Exactitud\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Exactitud en el conjunto de prueba:\")\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del modelo SVM que hemos obtenido muestran un rendimiento muy bueno. Vamos a desglosar los resultados y compararlos con los resultados del modelo Naive Bayes.\n",
    "\n",
    "### **Resultados del Modelo SVM**\n",
    "\n",
    "#### **Reporte de Clasificación**\n",
    "\n",
    "| Clase | Precision | Recall | F1-score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| **ham**  | 0.99      | 0.99   | 0.99     | 732     |\n",
    "| **spam** | 0.96      | 0.97   | 0.97     | 267     |\n",
    "| **Accuracy** |       |        | 0.98     | 999     |\n",
    "| **Macro avg** | 0.98  | 0.98   | 0.98     | 999     |\n",
    "| **Weighted avg** | 0.98 | 0.98 | 0.98     | 999     |\n",
    "\n",
    "#### **Matriz de Confusión**\n",
    "\n",
    "|        | Predicted ham | Predicted spam |\n",
    "|--------|---------------|----------------|\n",
    "| **Actual ham**  | 722           | 10             |\n",
    "| **Actual spam** | 8             | 259            |\n",
    "\n",
    "#### **Exactitud**\n",
    "\n",
    "- **Exactitud en el conjunto de prueba**: 0.982\n",
    "\n",
    "### **Comparación con el Modelo Naive Bayes**\n",
    "\n",
    "Aquí está el resumen de los resultados del modelo Naive Bayes para comparación:\n",
    "\n",
    "#### **Reporte de Clasificación**\n",
    "\n",
    "| Clase | Precision | Recall | F1-score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| **ham**  | 1.00      | 0.96   | 0.98     | 706     |\n",
    "| **spam** | 0.91      | 0.99   | 0.95     | 293     |\n",
    "| **Accuracy** |       |        | 0.97     | 999     |\n",
    "| **Macro avg** | 0.95  | 0.97   | 0.96     | 999     |\n",
    "| **Weighted avg** | 0.97 | 0.97 | 0.97     | 999     |\n",
    "\n",
    "#### **Matriz de Confusión**\n",
    "\n",
    "|        | Predicted ham | Predicted spam |\n",
    "|--------|---------------|----------------|\n",
    "| **Actual ham**  | 677           | 29             |\n",
    "| **Actual spam** | 3             | 290            |\n",
    "\n",
    "#### **Exactitud**\n",
    "\n",
    "- **Exactitud en el conjunto de prueba**: 0.958\n",
    "\n",
    "### **Análisis Comparativo**\n",
    "\n",
    "1. **Precisión**:\n",
    "   - **SVM**: 0.99 para `ham` y 0.96 para `spam`.\n",
    "   - **Naive Bayes**: 1.00 para `ham` y 0.91 para `spam`.\n",
    "\n",
    "2. **Recall**:\n",
    "   - **SVM**: 0.99 para `ham` y 0.97 para `spam`.\n",
    "   - **Naive Bayes**: 0.96 para `ham` y 0.99 para `spam`.\n",
    "\n",
    "3. **F1-score**:\n",
    "   - **SVM**: 0.99 para `ham` y 0.97 para `spam`.\n",
    "   - **Naive Bayes**: 0.98 para `ham` y 0.95 para `spam`.\n",
    "\n",
    "4. **Exactitud**:\n",
    "   - **SVM**: 0.982\n",
    "   - **Naive Bayes**: 0.958\n",
    "\n",
    "5. **Matriz de Confusión**:\n",
    "   - **SVM** tiene menos falsos positivos y falsos negativos en comparación con Naive Bayes, especialmente para la clase `ham`, donde ha clasificado correctamente la mayoría de los casos.\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "El modelo SVM ha mostrado una mejor precisión general, recall y F1-score en comparación con el modelo Naive Bayes en el conjunto de prueba. La exactitud del modelo SVM es más alta (0.982 frente a 0.958), y la matriz de confusión indica que el modelo SVM ha cometido menos errores en la clasificación, especialmente para los casos de `ham`.\n",
    "\n",
    "Esto sugiere que el modelo SVM es mejor para tu problema de clasificación en este caso específico. Sin embargo, es importante considerar otros factores como el tiempo de entrenamiento, la interpretabilidad y el ajuste del modelo antes de tomar una decisión final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
