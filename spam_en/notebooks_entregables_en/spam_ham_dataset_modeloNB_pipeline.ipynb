{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_smote_pipeline.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Cargar el dataset modificado\n",
    "df_modificado = pd.read_csv('../data_en/spam_ham_dataset_modificado.csv')\n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_modificado['text'], df_modificado['label_num'], test_size=0.2, random_state=42, stratify=df_modificado['label_num'])\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación (75% entrenamiento, 25% validación)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
    "\n",
    "# Vectorización usando TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Aplicar SMOTE solo en el conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = ImbPipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('smote', smote),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el modelo y el vectorizador\n",
    "joblib.dump(pipeline, '../modelos_y_vectorizadores_en/naive_bayes_smote_pipeline.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación en el conjunto de prueba:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       706\n",
      "           1       0.90      0.99      0.94       293\n",
      "\n",
      "    accuracy                           0.96       999\n",
      "   macro avg       0.95      0.97      0.96       999\n",
      "weighted avg       0.97      0.96      0.96       999\n",
      "\n",
      "Matriz de Confusión en el conjunto de prueba:\n",
      "[[674  32]\n",
      " [  4 289]]\n",
      "Exactitud en el conjunto de prueba:\n",
      "0.963963963963964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Cargar el modelo previamente guardado\n",
    "pipeline = joblib.load('../modelos_y_vectorizadores_en/naive_bayes_smote_pipeline.pkl')\n",
    "\n",
    "# Cargar el conjunto de datos de prueba\n",
    "X_test = pd.read_csv('../data_en/X_test.csv')\n",
    "y_test = pd.read_csv('../data_en/y_test.csv')\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_test_pred = pipeline.predict(X_test['text'])\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "print(\"Reporte de Clasificación en el conjunto de prueba:\")\n",
    "print(classification_report(y_test['label_num'], y_test_pred))\n",
    "\n",
    "print(\"Matriz de Confusión en el conjunto de prueba:\")\n",
    "print(confusion_matrix(y_test['label_num'], y_test_pred))\n",
    "\n",
    "print(\"Exactitud en el conjunto de prueba:\")\n",
    "print(accuracy_score(y_test['label_num'], y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos al aplicar SMOTE para balancear el dataset muestran una mejora notable en el rendimiento del modelo. Aquí está un análisis detallado de las métricas:\n",
    "\n",
    "### Análisis del Reporte de Clasificación\n",
    "\n",
    "El reporte de clasificación después de aplicar SMOTE es el siguiente:\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      0.95      0.97       706\n",
    "           1       0.90      0.99      0.94       293\n",
    "\n",
    "    accuracy                           0.96       999\n",
    "   macro avg       0.95      0.97      0.96       999\n",
    "weighted avg       0.97      0.96      0.96       999\n",
    "```\n",
    "\n",
    "#### **Interpretación:**\n",
    "\n",
    "1. **Precisión y Recuerdo**:\n",
    "   - **`ham` (0)**:\n",
    "     - **Precisión**: 0.99 (99% de las veces que el modelo predice `ham`, es correcto).\n",
    "     - **Recuerdo**: 0.95 (95% de los verdaderos `ham` son identificados correctamente).\n",
    "   - **`spam` (1)**:\n",
    "     - **Precisión**: 0.90 (90% de las veces que el modelo predice `spam`, es correcto).\n",
    "     - **Recuerdo**: 0.99 (99% de los verdaderos `spam` son identificados correctamente).\n",
    "\n",
    "2. **F1-Score**:\n",
    "   - **`ham` (0)**: 0.97, lo cual indica un buen equilibrio entre precisión y recuerdo.\n",
    "   - **`spam` (1)**: 0.94, que también es bastante bueno y muestra un buen equilibrio.\n",
    "\n",
    "3. **Exactitud**:\n",
    "   - La exactitud general del modelo es 0.96 (96%), lo que indica que el modelo hace predicciones correctas el 96% de las veces.\n",
    "\n",
    "4. **Promedio Macro y Ponderado**:\n",
    "   - **Macro Avg**: Promedia las métricas sin considerar el soporte. Muestra un buen rendimiento global, con un F1-Score de 0.96.\n",
    "   - **Weighted Avg**: Promedia las métricas considerando el soporte. El rendimiento ponderado también es alto, con un F1-Score de 0.96.\n",
    "\n",
    "### Análisis de la Matriz de Confusión\n",
    "\n",
    "La matriz de confusión es:\n",
    "\n",
    "```\n",
    "[[674  32]\n",
    " [  4 289]]\n",
    "```\n",
    "\n",
    "- **True Negatives (TN)**: 674 (Mensajes `ham` correctamente clasificados como `ham`).\n",
    "- **False Positives (FP)**: 32 (Mensajes `ham` clasificados incorrectamente como `spam`).\n",
    "- **False Negatives (FN)**: 4 (Mensajes `spam` clasificados incorrectamente como `ham`).\n",
    "- **True Positives (TP)**: 289 (Mensajes `spam` correctamente clasificados como `spam`).\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "- **Mejoras Notables**:\n",
    "  - **Recuerdo para `spam` (1)** ha mejorado significativamente (0.99), lo cual es crucial, especialmente si el costo de perder mensajes `spam` es alto.\n",
    "  - **Precisión para `spam` (1)** también es alta (0.90), lo que indica que el modelo predice `spam` con buena exactitud.\n",
    "\n",
    "- **Precisión Alta para `ham` (0)**:\n",
    "  - La precisión para `ham` sigue siendo alta (0.99), y el modelo mantiene un buen recuerdo (0.95).\n",
    "\n",
    "- **Balance entre Precisión y Recuerdo**:\n",
    "  - El F1-Score para ambas clases muestra un buen equilibrio, indicando que el modelo está funcionando bien en general.\n",
    "\n",
    "### Recomendaciones Adicionales\n",
    "\n",
    "1. **Experimentar con Otros Algoritmos**:\n",
    "   - Considera probar otros algoritmos de clasificación, como Random Forest, SVM, o redes neuronales, para comparar el rendimiento.\n",
    "\n",
    "2. **Optimización Adicional**:\n",
    "   - Ajusta hiperparámetros del modelo o realiza una búsqueda en cuadrícula para mejorar aún más el rendimiento.\n",
    "\n",
    "3. **Validación Cruzada**:\n",
    "   - Realiza una validación cruzada para obtener una estimación más robusta del rendimiento del modelo en datos no vistos.\n",
    "\n",
    "4. **Revisión de Datos**:\n",
    "   - Asegúrate de revisar el dataset para identificar cualquier posible sesgo o problemas adicionales que puedan afectar el rendimiento del modelo.\n",
    "\n",
    "En resumen, la aplicación de SMOTE ha tenido un impacto positivo en el rendimiento del modelo, especialmente en el manejo de la clase minoritaria (`spam`), y el modelo muestra un buen rendimiento general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para identificar los casos donde el modelo se ha equivocado en el conjunto de prueba, se pueden seguir estos pasos:\n",
    "\n",
    "Realizar las predicciones en el conjunto de prueba.\n",
    "Comparar las predicciones con las etiquetas reales.\n",
    "Identificar y mostrar los casos donde las predicciones no coinciden con las etiquetas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casos donde el modelo se ha equivocado:\n",
      "                                                  text  actual  predicted\n",
      "6    registration confirmation from spinner . com\\r...       0          1\n",
      "19   http : / / www . pge - texas . com / www / gtt...       0          1\n",
      "73   your amazon . com order ( # 104 - 9670681 - 03...       0          1\n",
      "88   thanks from ken walther\\r\\ni can not begin to ...       0          1\n",
      "132  this week ' s woodworking tip . . . follow - u...       0          1\n",
      "232  lacy ' s eye exam\\r\\nhi bubba !\\r\\nlacy got he...       0          1\n",
      "247  your amazon . com order ( # 104 - 9670681 - 03...       0          1\n",
      "388  fw : whose needs ? ? ? ? ? ? ? ?\\r\\n> perfect ...       0          1\n",
      "418  welcome to woodworkingtips . com !\\r\\n* please...       0          1\n",
      "448  ? ? ? ? ? ? ? ? erp !\\r\\n? ????? ? ?  ? ? ????...       1          0\n",
      "491  i can receive attachments on my hotmail addres...       0          1\n",
      "566  invitation to dinner\\r\\nmusic can be started b...       0          1\n",
      "585  jeff ' s corner - - a message from the ceo on ...       0          1\n",
      "602  digitize your memories with compaq scanners\\r\\...       0          1\n",
      "643  your order with amazon . com ( # 102 - 6820014...       0          1\n",
      "645  aol instant messenger confirmation\\r\\nthank yo...       0          1\n",
      "665  prom dress shopping\\r\\nhi , just wanted to let...       0          1\n",
      "666  lacy ' s eye exam\\r\\nplease respond to hi bubb...       0          1\n",
      "712  curtains\\r\\nhey ! i ' v almost got the curtain...       0          1\n",
      "755  here ' s the list , dirty , but it ' s a list ...       0          1\n",
      "762  happy birthday ! ! !\\r\\ndaren ,\\r\\ni contend t...       0          1\n",
      "780                   christmas tree farm pictures\\r\\n       0          1\n",
      "784  new version of stack manager\\r\\nintroduction\\r...       0          1\n",
      "797  fw : quips\\r\\n> remember , amateurs built the ...       0          1\n",
      "799  $ 5 for cd ' s dvd ' s expires soon at half . ...       0          1\n",
      "838  the new power company ; reserved share program...       0          1\n",
      "852  re :\\r\\nthu , 06 may 2004 04 : 17 : 35 - 0500\\...       1          0\n",
      "858  enron announcement\\r\\ncar rental options for e...       0          1\n",
      "873  please note my new email address\\r\\neffective ...       0          1\n",
      "883  iwon member news : iwon tv show , new year of ...       0          1\n",
      "886  barnhart sat , 23 jul 2005 05 : 28 : 20 + 0400...       1          0\n",
      "932  your amazon . com order ( # 104 - 9670681 - 03...       0          1\n",
      "933  income tax\\r\\nhey ! tonya said to staple copy ...       0          1\n",
      "959  fw : the odds are against them\\r\\nthere is no ...       0          1\n",
      "969  re : network at wed , 11 aug 2004 18 : 51 : 29...       1          0\n",
      "987  welcome to aol instant messenger !\\r\\nwelcome ...       0          1\n"
     ]
    }
   ],
   "source": [
    "# Identificar los casos donde el modelo se ha equivocado\n",
    "\n",
    "# Crear un DataFrame con las predicciones y las etiquetas reales\n",
    "results_df = pd.DataFrame({'text': X_test['text'], 'actual': y_test['label_num'], 'predicted': y_test_pred})\n",
    "\n",
    "# Filtrar los casos donde las predicciones no coinciden con las etiquetas reales\n",
    "incorrect_cases = results_df[results_df['actual'] != results_df['predicted']]\n",
    "\n",
    "# Mostrar los casos incorrectos\n",
    "print(\"Casos donde el modelo se ha equivocado:\")\n",
    "print(incorrect_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casos donde el modelo se ha equivocado:\n",
      "                                                  text actual predicted\n",
      "6    registration confirmation from spinner . com\\r...    ham      spam\n",
      "19   http : / / www . pge - texas . com / www / gtt...    ham      spam\n",
      "73   your amazon . com order ( # 104 - 9670681 - 03...    ham      spam\n",
      "88   thanks from ken walther\\r\\ni can not begin to ...    ham      spam\n",
      "132  this week ' s woodworking tip . . . follow - u...    ham      spam\n",
      "232  lacy ' s eye exam\\r\\nhi bubba !\\r\\nlacy got he...    ham      spam\n",
      "247  your amazon . com order ( # 104 - 9670681 - 03...    ham      spam\n",
      "388  fw : whose needs ? ? ? ? ? ? ? ?\\r\\n> perfect ...    ham      spam\n",
      "418  welcome to woodworkingtips . com !\\r\\n* please...    ham      spam\n",
      "448  ? ? ? ? ? ? ? ? erp !\\r\\n? ????? ? ?  ? ? ????...   spam       ham\n",
      "491  i can receive attachments on my hotmail addres...    ham      spam\n",
      "566  invitation to dinner\\r\\nmusic can be started b...    ham      spam\n",
      "585  jeff ' s corner - - a message from the ceo on ...    ham      spam\n",
      "602  digitize your memories with compaq scanners\\r\\...    ham      spam\n",
      "643  your order with amazon . com ( # 102 - 6820014...    ham      spam\n",
      "645  aol instant messenger confirmation\\r\\nthank yo...    ham      spam\n",
      "665  prom dress shopping\\r\\nhi , just wanted to let...    ham      spam\n",
      "666  lacy ' s eye exam\\r\\nplease respond to hi bubb...    ham      spam\n",
      "712  curtains\\r\\nhey ! i ' v almost got the curtain...    ham      spam\n",
      "755  here ' s the list , dirty , but it ' s a list ...    ham      spam\n",
      "762  happy birthday ! ! !\\r\\ndaren ,\\r\\ni contend t...    ham      spam\n",
      "780                   christmas tree farm pictures\\r\\n    ham      spam\n",
      "784  new version of stack manager\\r\\nintroduction\\r...    ham      spam\n",
      "797  fw : quips\\r\\n> remember , amateurs built the ...    ham      spam\n",
      "799  $ 5 for cd ' s dvd ' s expires soon at half . ...    ham      spam\n",
      "838  the new power company ; reserved share program...    ham      spam\n",
      "852  re :\\r\\nthu , 06 may 2004 04 : 17 : 35 - 0500\\...   spam       ham\n",
      "858  enron announcement\\r\\ncar rental options for e...    ham      spam\n",
      "873  please note my new email address\\r\\neffective ...    ham      spam\n",
      "883  iwon member news : iwon tv show , new year of ...    ham      spam\n",
      "886  barnhart sat , 23 jul 2005 05 : 28 : 20 + 0400...   spam       ham\n",
      "932  your amazon . com order ( # 104 - 9670681 - 03...    ham      spam\n",
      "933  income tax\\r\\nhey ! tonya said to staple copy ...    ham      spam\n",
      "959  fw : the odds are against them\\r\\nthere is no ...    ham      spam\n",
      "969  re : network at wed , 11 aug 2004 18 : 51 : 29...   spam       ham\n",
      "987  welcome to aol instant messenger !\\r\\nwelcome ...    ham      spam\n"
     ]
    }
   ],
   "source": [
    "# Mapear las etiquetas numéricas a etiquetas textuales\n",
    "label_mapping = {0: 'ham', 1: 'spam'}\n",
    "y_test_mapped = y_test['label_num'].map(label_mapping)\n",
    "y_test_pred_mapped = pd.Series(y_test_pred).map(label_mapping)\n",
    "\n",
    "# Identificar los casos donde el modelo se ha equivocado\n",
    "# Crear un DataFrame con las predicciones y las etiquetas reales\n",
    "results_df = pd.DataFrame({'text': X_test['text'], 'actual': y_test_mapped, 'predicted': y_test_pred_mapped})\n",
    "\n",
    "# Filtrar los casos donde las predicciones no coinciden con las etiquetas reales\n",
    "incorrect_cases = results_df[results_df['actual'] != results_df['predicted']]\n",
    "\n",
    "# Mostrar los casos incorrectos\n",
    "print(\"Casos donde el modelo se ha equivocado:\")\n",
    "print(incorrect_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando los casos donde el modelo se ha equivocado, podemos identificar áreas de mejora para ajustar y mejorar el modelo de clasificación de spam. Aquí hay algunas posibles acciones:\n",
    "\n",
    "1. Analizar los Errores del Modelo\n",
    "Ham Clasificado como Spam:\n",
    "\n",
    "Mensajes de confirmación, pedidos de Amazon, correos electrónicos personales, etc., han sido clasificados incorrectamente como spam.\n",
    "Estos errores pueden estar relacionados con características específicas en el texto que el modelo ha asociado incorrectamente con el spam.\n",
    "Spam Clasificado como Ham:\n",
    "\n",
    "Algunos mensajes spam, como aquellos con contenido publicitario explícito, no han sido identificados correctamente.\n",
    "Esto podría sugerir que el modelo necesita más ejemplos o características específicas para identificar mejor estos patrones.\n",
    "2. Mejorar la Representación del Texto\n",
    "N-grams:\n",
    "Utilizar n-grams (bigramas, trigramas, etc.) en lugar de solo unigrams puede ayudar a capturar más contexto en el texto.\n",
    "python\n",
    "Copy code\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # bigramas\n",
    "Stemming y Lemmatization:\n",
    "Aplicar stemming o lemmatization para reducir las palabras a su forma raíz y reducir la dimensionalidad del texto.\n",
    "3. Ajustar el Modelo\n",
    "Modelos Más Avanzados:\n",
    "Probar modelos más avanzados como Random Forest, Gradient Boosting, o incluso modelos basados en redes neuronales.\n",
    "Considerar el uso de modelos específicos para NLP como BERT o GPT-3.\n",
    "4. Revisión y Expansión del Dataset\n",
    "Balanceo del Dataset:\n",
    "Aunque SMOTE ayuda a balancear el dataset, es posible que se necesite más diversidad en los ejemplos de entrenamiento.\n",
    "Revisar y Etiquetar Datos Manualmente:\n",
    "Revisar manualmente algunos de los errores para mejorar la calidad del dataset.\n",
    "5. Tuning de Hiperparámetros\n",
    "Grid Search o Random Search:\n",
    "Realizar una búsqueda de hiperparámetros para encontrar los mejores parámetros para el modelo actual.\n",
    "6. Filtrado de Características\n",
    "Eliminar Caracteres Especiales:\n",
    "Eliminar caracteres especiales que puedan no aportar valor significativo.\n",
    "python\n",
    "Copy code\n",
    "df_modificado['text'] = df_modificado['text'].str.replace('[^a-zA-Z0-9\\s]', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examinemos algunos nuevos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje 'this is your last opportunity' ha sido clasificado como: spam\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de texto nuevo\n",
    "new_example = [\"this is your last opportunity\"]\n",
    "\n",
    "# Usar el pipeline para predecir la clase del nuevo ejemplo\n",
    "prediction = pipeline.predict(new_example)\n",
    "\n",
    "# Convertir la predicción a etiqueta legible\n",
    "label_map = {0: 'ham', 1: 'spam'}\n",
    "predicted_label = label_map[prediction[0]]\n",
    "\n",
    "print(f\"El mensaje '{new_example[0]}' ha sido clasificado como: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje 'Call me if you are alone' ha sido clasificado como: ham\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de texto nuevo\n",
    "new_example = [\"Call me if you are alone\"]\n",
    "\n",
    "# Usar el pipeline para predecir la clase del nuevo ejemplo\n",
    "prediction = pipeline.predict(new_example)\n",
    "\n",
    "# Convertir la predicción a etiqueta legible\n",
    "label_map = {0: 'ham', 1: 'spam'}\n",
    "predicted_label = label_map[prediction[0]]\n",
    "\n",
    "print(f\"El mensaje '{new_example[0]}' ha sido clasificado como: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje 'Bring some beers' ha sido clasificado como: spam\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de texto nuevo\n",
    "new_example = [\"Bring some beers\"]\n",
    "\n",
    "# Usar el pipeline para predecir la clase del nuevo ejemplo\n",
    "prediction = pipeline.predict(new_example)\n",
    "\n",
    "# Convertir la predicción a etiqueta legible\n",
    "label_map = {0: 'ham', 1: 'spam'}\n",
    "predicted_label = label_map[prediction[0]]\n",
    "\n",
    "print(f\"El mensaje '{new_example[0]}' ha sido clasificado como: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mensaje 'I forgot to tell you something' ha sido clasificado como: ham\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de texto nuevo\n",
    "new_example = [\"I forgot to tell you something\"]\n",
    "\n",
    "# Usar el pipeline para predecir la clase del nuevo ejemplo\n",
    "prediction = pipeline.predict(new_example)\n",
    "\n",
    "# Convertir la predicción a etiqueta legible\n",
    "label_map = {0: 'ham', 1: 'spam'}\n",
    "predicted_label = label_map[prediction[0]]\n",
    "\n",
    "print(f\"El mensaje '{new_example[0]}' ha sido clasificado como: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
