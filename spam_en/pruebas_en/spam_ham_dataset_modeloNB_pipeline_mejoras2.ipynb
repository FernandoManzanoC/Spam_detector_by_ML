{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este notebook corrijo los errores del spam_ham_dataset_modeloNB_pipeline_mejoras.ipynb \n",
    "\n",
    "Dado los resultados aunque buenos decido aplicar SVM al dataset en inglés porque da menos error en los Reporte de los ham incorrectamente etiquetados como spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación en el conjunto de validación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.96      0.98       707\n",
      "        spam       0.91      0.99      0.95       292\n",
      "\n",
      "    accuracy                           0.97       999\n",
      "   macro avg       0.95      0.98      0.96       999\n",
      "weighted avg       0.97      0.97      0.97       999\n",
      "\n",
      "Matriz de Confusión en el conjunto de validación:\n",
      "[[679  28]\n",
      " [  2 290]]\n",
      "Exactitud en el conjunto de validación:\n",
      "0.96996996996997\n",
      "Reporte de Clasificación en el conjunto de prueba:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.95      0.97       706\n",
      "        spam       0.88      0.99      0.93       293\n",
      "\n",
      "    accuracy                           0.96       999\n",
      "   macro avg       0.94      0.97      0.95       999\n",
      "weighted avg       0.96      0.96      0.96       999\n",
      "\n",
      "Matriz de Confusión en el conjunto de prueba:\n",
      "[[668  38]\n",
      " [  3 290]]\n",
      "Exactitud en el conjunto de prueba:\n",
      "0.958958958958959\n",
      "Longitud de X_test: 999\n",
      "Longitud de y_test: 999\n",
      "Longitud de y_test_pred: 999\n",
      "Casos donde el modelo se ha equivocado:\n",
      "                                                  text actual predicted\n",
      "6    registr confirm from spinner . com thank you f...    ham      spam\n",
      "10   young famili egg hunt bammelyoungfamili - - - ...    ham      spam\n",
      "19   http : / / www . pge - texa . com / www / gtt ...    ham      spam\n",
      "45   enron ? ? ? keep up the good work . ? we at ho...    ham      spam\n",
      "73   your amazon . com order ( # 104 - 9670681 - 03...    ham      spam\n",
      "88   thank from ken walther i can not begin to expr...    ham      spam\n",
      "132  this week ' s woodwork tip . . . follow - up g...    ham      spam\n",
      "232  laci ' s eye exam hi bubba ! laci got her eye ...    ham      spam\n",
      "247  your amazon . com order ( # 104 - 9670681 - 03...    ham      spam\n",
      "258  just want to say goodby . i truli appreci all ...    ham      spam\n",
      "314  good answer '' . . . if my peopl , who are cal...    ham      spam\n",
      "377  fw : tribut to america regard , ami brock hbd ...    ham      spam\n",
      "388  fw : whose need ? ? ? ? ? ? ? ? > perfect ! ! ...    ham      spam\n",
      "418  welcom to woodworkingtip . com ! * pleas save ...    ham      spam\n",
      "419  from your clerk . it been great ! i just want ...    ham      spam\n",
      "448  ? ? ? ? ? ? ? ? erp ! ? ? ? ? ? ? ? ? ? ? ? ? ...   spam       ham\n",
      "491  i can receiv attach on my hotmail address . i ...    ham      spam\n",
      "514  fw : re : he rbv i agr a see the . htm attach ...   spam       ham\n",
      "566  invit to dinner music can be start by click on...    ham      spam\n",
      "585  jeff ' s corner - - a messag from the ceo on t...    ham      spam\n",
      "602  digit your memori with compaq scanner tire of ...    ham      spam\n",
      "643  your order with amazon . com ( # 102 - 6820014...    ham      spam\n",
      "645  aol instant messeng confirm thank you for regi...    ham      spam\n",
      "666  laci ' s eye exam pleas respond to hi bubba ! ...    ham      spam\n",
      "671  playgroup pictur - old mcdonald ' s farm = = =...    ham      spam\n",
      "712  curtain hey ! i ' v almost got the curtain fin...    ham      spam\n",
      "762  happi birthday ! ! ! daren , i contend that a ...    ham      spam\n",
      "780                          christma tree farm pictur    ham      spam\n",
      "784  new version of stack manag introduct in respon...    ham      spam\n",
      "785  daren , i have no problem stick around with th...    ham      spam\n",
      "797  fw : quip > rememb , amateur built the ark . >...    ham      spam\n",
      "799  $ 5 for cd ' s dvd ' s expir soon at half . co...    ham      spam\n",
      "838  the new power compani ; reserv share program e...    ham      spam\n",
      "858  enron announc car rental option for enron trav...    ham      spam\n",
      "873  pleas note my new email address effect today ,...    ham      spam\n",
      "883  iwon member news : iwon tv show , new year of ...    ham      spam\n",
      "886  barnhart sat , 23 jul 2005 05 : 28 : 20 + 0400...   spam       ham\n",
      "932  your amazon . com order ( # 104 - 9670681 - 03...    ham      spam\n",
      "933  incom tax hey ! tonya said to stapl copi b of ...    ham      spam\n",
      "959  fw : the odd are against them there is no way ...    ham      spam\n",
      "987  welcom to aol instant messeng ! welcom to the ...    ham      spam\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Función de stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_text(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in word_tokenize(text)])\n",
    "\n",
    "# Cargar el dataset modificado\n",
    "df_modificado = pd.read_csv('../data_en/spam_ham_dataset_modificado.csv')\n",
    "\n",
    "\n",
    "# Aplicar stemming\n",
    "df_modificado['text'] = df_modificado['text'].apply(stem_text)\n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento, validación y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_modificado['text'], df_modificado['label_num'], test_size=0.2, random_state=42, stratify=df_modificado['label_num'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
    "\n",
    "# Crear y entrenar el pipeline con bigramas y stemming, usando SMOTE\n",
    "pipeline = ImbPipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "print(\"Reporte de Clasificación en el conjunto de validación:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['ham', 'spam']))\n",
    "print(\"Matriz de Confusión en el conjunto de validación:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "print(\"Exactitud en el conjunto de validación:\")\n",
    "print(accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "# Guardar el modelo y el vectorizador\n",
    "joblib.dump(pipeline, '../modelos_y_vectorizadores_en/naive_bayes_smote_pipeline_improved.pkl')\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(\"Reporte de Clasificación en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['ham', 'spam']))\n",
    "print(\"Matriz de Confusión en el conjunto de prueba:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Exactitud en el conjunto de prueba:\")\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Verifica la longitud de las predicciones y datos de prueba\n",
    "print(\"Longitud de X_test:\", len(X_test))\n",
    "print(\"Longitud de y_test:\", len(y_test))\n",
    "print(\"Longitud de y_test_pred:\", len(y_test_pred))\n",
    "\n",
    "# Alinear los índices para crear el DataFrame de resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'text': X_test.reset_index(drop=True),  # Resetear índices para asegurar alineación\n",
    "    'actual': y_test.reset_index(drop=True).map({0: 'ham', 1: 'spam'}),\n",
    "    'predicted': pd.Series(y_test_pred).map({0: 'ham', 1: 'spam'})\n",
    "})\n",
    "\n",
    "# Identificar los casos donde el modelo se ha equivocado\n",
    "incorrect_cases = results_df[results_df['actual'] != results_df['predicted']]\n",
    "\n",
    "# Mostrar los casos incorrectos\n",
    "print(\"Casos donde el modelo se ha equivocado:\")\n",
    "print(incorrect_cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es sin entrenar el modelo con todo train y validacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del modelo Naive Bayes (NB) en el conjunto de prueba son bastante buenos, indicando un rendimiento sólido en la clasificación de mensajes como \"ham\" (no deseado) o \"spam\" (deseado). Aquí está un análisis detallado de estos resultados:\n",
    "\n",
    "### Reporte de Clasificación\n",
    "\n",
    "#### Clase \"ham\":\n",
    "- **Precisión (Precision)**: 1.00 - El modelo predice correctamente todas las instancias etiquetadas como \"ham\". No hay falsos positivos.\n",
    "- **Recall (Sensibilidad)**: 0.95 - El modelo identifica correctamente el 95% de las instancias reales de \"ham\".\n",
    "- **F1-score**: 0.97 - La media armónica de precisión y recall es alta, indicando un excelente rendimiento en esta clase.\n",
    "- **Support (Soporte)**: 706 - El número de instancias de \"ham\" en el conjunto de prueba.\n",
    "\n",
    "#### Clase \"spam\":\n",
    "- **Precisión (Precision)**: 0.88 - El modelo predice correctamente el 88% de las instancias etiquetadas como \"spam\".\n",
    "- **Recall (Sensibilidad)**: 0.99 - El modelo identifica correctamente el 99% de las instancias reales de \"spam\".\n",
    "- **F1-score**: 0.93 - La media armónica de precisión y recall es buena, aunque no tan alta como para \"ham\".\n",
    "- **Support (Soporte)**: 293 - El número de instancias de \"spam\" en el conjunto de prueba.\n",
    "\n",
    "#### Totales:\n",
    "- **Accuracy (Precisión global)**: 0.96 - El modelo clasifica correctamente el 96% de las instancias en el conjunto de prueba.\n",
    "- **Macro avg** (Promedio macro):\n",
    "  - **Precision**: 0.94\n",
    "  - **Recall**: 0.97\n",
    "  - **F1-score**: 0.95\n",
    "- **Weighted avg** (Promedio ponderado):\n",
    "  - **Precision**: 0.96\n",
    "  - **Recall**: 0.96\n",
    "  - **F1-score**: 0.96\n",
    "\n",
    "### Matriz de Confusión\n",
    "\n",
    "#### Interpretación:\n",
    "- **668 verdaderos negativos (ham correctamente clasificado)**\n",
    "- **38 falsos positivos (ham incorrectamente clasificado como spam)**\n",
    "- **3 falsos negativos (spam incorrectamente clasificado como ham)**\n",
    "- **290 verdaderos positivos (spam correctamente clasificado)**\n",
    "\n",
    "### Análisis Detallado\n",
    "\n",
    "1. **Precisión y Recall**:\n",
    "   - La **precisión** para \"ham\" es perfecta, lo que significa que todos los mensajes predichos como \"ham\" son realmente \"ham\". Para \"spam\", la precisión es alta pero no perfecta, indicando que hay algunos mensajes predichos como \"spam\" que no lo son.\n",
    "   - El **recall** es muy alto para ambas clases, especialmente para \"spam\", lo que significa que casi todos los mensajes de \"spam\" reales son identificados correctamente.\n",
    "\n",
    "2. **F1-Score**:\n",
    "   - Los altos valores de F1-score para ambas clases indican que el modelo tiene un buen equilibrio entre precisión y recall. La ligera diferencia entre las clases refleja que la clasificación de \"spam\" es un poco más difícil para el modelo en términos de precisión.\n",
    "\n",
    "3. **Accuracy**:\n",
    "   - Una precisión global del 96% sugiere que el modelo tiene un rendimiento muy alto en general, con solo un pequeño porcentaje de errores.\n",
    "\n",
    "4. **Matriz de Confusión**:\n",
    "   - La matriz de confusión muestra que el modelo comete muy pocos errores, con solo 38 falsos positivos y 3 falsos negativos. Esto refuerza la idea de que el modelo es particularmente efectivo en identificar \"spam\" con muy pocos mensajes de \"spam\" clasificados incorrectamente como \"ham\".\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "El modelo Naive Bayes muestra un buen rendimiento en el conjunto de prueba, especialmente en términos de recall para ambas clases y precisión para la clase \"ham\". Aunque la precisión para \"spam\" es ligeramente inferior, sigue siendo alta, y el bajo número de falsos negativos indica que el modelo es muy eficaz para identificar correctamente los mensajes de \"spam\". En general, el modelo proporciona una clasificación confiable con una precisión global del 96%, lo que lo convierte en una herramienta valiosa para la clasificación de mensajes de \"ham\" y \"spam\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
