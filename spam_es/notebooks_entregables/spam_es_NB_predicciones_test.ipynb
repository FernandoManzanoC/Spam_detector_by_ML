{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1: Cargar el Modelo Entrenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle  \n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "\n",
    "with open('../modelos_y_vectorizadores/modelo_naive_bayes.pkl', 'rb') as archivo: \n",
    "     loaded_model = pickle.load(archivo)\n",
    "\n",
    "# Verificar que el modelo se haya cargado correctamente\n",
    "print(\"Modelo cargado:\", loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Cargar el vectorizador\n",
    "vectorizador = joblib.load('../modelos_y_vectorizadores/vectorizador.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2: Preprocesar test.csv\n",
    "\n",
    "Ahora, procede a cargar y preprocesar test.csv de la misma manera que lo hicimos con train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensaje</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tu devolucion esta siendo procesada</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gana dinero por compartir tus opiniones</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recordatorio de tu cita con el nutricionista</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quema grasa abdominal con este suplemento</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agradecemos tu preferencia</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mensaje  tipo\n",
       "0           Tu devolucion esta siendo procesada   ham\n",
       "1       Gana dinero por compartir tus opiniones  spam\n",
       "2  Recordatorio de tu cita con el nutricionista   ham\n",
       "3     Quema grasa abdominal con este suplemento  spam\n",
       "4                    Agradecemos tu preferencia   ham"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar test.csv\n",
    "test_df = pd.read_csv('../data_es/test.csv')\n",
    "\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensaje</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Tu devolucion esta siendo procesada</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    mensaje tipo\n",
       "count                                   209  209\n",
       "unique                                  209    2\n",
       "top     Tu devolucion esta siendo procesada  ham\n",
       "freq                                      1  109"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   mensaje  209 non-null    object\n",
      " 1   tipo     209 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensajes duplicados:\n",
      "Empty DataFrame\n",
      "Columns: [mensaje, tipo]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Contar los mensajes duplicados\n",
    "duplicados = test_df[test_df.duplicated(['mensaje'], keep=False)]\n",
    "\n",
    "# Mostrar los mensajes duplicados\n",
    "print(\"Mensajes duplicados:\")\n",
    "print(duplicados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mensaje', 'tipo'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los nombres de las columnas del dataset\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          mensaje  \\\n",
      "0             Tu devolucion esta siendo procesada   \n",
      "1         Gana dinero por compartir tus opiniones   \n",
      "2    Recordatorio de tu cita con el nutricionista   \n",
      "3       Quema grasa abdominal con este suplemento   \n",
      "4                      Agradecemos tu preferencia   \n",
      "5             Obten tu score crediticio sin costo   \n",
      "6    Firma el acuerdo de confidencialidad adjunto   \n",
      "7         Aprovecha descuentos exclusivos para ti   \n",
      "8             Confirmamos que recibimos tu pedido   \n",
      "9  Desata tu potencial sexual con estas pastillas   \n",
      "\n",
      "                 mensaje_limpio_stopwords  \n",
      "0             devolucion siendo procesada  \n",
      "1         gana dinero compartir opiniones  \n",
      "2         recordatorio cita nutricionista  \n",
      "3        quema grasa abdominal suplemento  \n",
      "4                 agradecemos preferencia  \n",
      "5            obten score crediticio costo  \n",
      "6  firma acuerdo confidencialidad adjunto  \n",
      "7         aprovecha descuentos exclusivos  \n",
      "8            confirmamos recibimos pedido  \n",
      "9       desata potencial sexual pastillas  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ferna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_sp = stopwords.words('spanish')\n",
    "\n",
    "# Agregar palabras adicionales que no aporten significado en este contexto específico\n",
    "stopwords_sp.extend(['este', 'nuestro', 'con', 'para', 'esta'])  # Podemos ajustar esta lista según necesitemos\n",
    "\n",
    "# Función para limpiar el texto y filtrar stopwords\n",
    "def limpiar_texto_con_stopwords(texto):\n",
    "    texto = re.sub(r'\\W', ' ', texto) # Eliminar caracteres no alfanuméricos\n",
    "    texto = texto.lower() # Convertir a minúsculas\n",
    "    texto = re.sub(r'\\s+', ' ', texto) # Eliminar espacios extra\n",
    "    palabras = texto.split()\n",
    "    palabras_filtradas = [palabra for palabra in palabras if palabra not in stopwords_sp]\n",
    "    return ' '.join(palabras_filtradas)\n",
    "\n",
    "# Aplicar limpieza con filtro de stopwords a los mensajes\n",
    "test_df['mensaje_limpio_stopwords'] = test_df['mensaje'].apply(limpiar_texto_con_stopwords)\n",
    "\n",
    "# Mostrar los mensajes limpios con filtrado de stopwords\n",
    "print(test_df[['mensaje', 'mensaje_limpio_stopwords']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorización de los Mensajes de Test\n",
    "limpios de test_df usando el vectorizador cargado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar transformación usando el vectorizador cargado\n",
    "X_test = vectorizador.transform(test_df['mensaje_limpio_stopwords'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacer Predicciones con el Modelo\n",
    "El modelo Naive Bayes cargado para hacer predicciones sobre X_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      0.83      0.87       109\n",
      "        spam       0.83      0.91      0.87       100\n",
      "\n",
      "    accuracy                           0.87       209\n",
      "   macro avg       0.87      0.87      0.87       209\n",
      "weighted avg       0.87      0.87      0.87       209\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[90 19]\n",
      " [ 9 91]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predecir con el modelo cargado\n",
    "y_pred_test = loaded_model.predict(X_test)\n",
    "\n",
    "# Convertir etiquetas numéricas a strings ('ham' y 'spam')\n",
    "y_pred_str = ['spam' if pred == 1 else 'ham' for pred in y_pred_test]\n",
    "\n",
    "# Obtener métricas de evaluación\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(test_df['tipo'], y_pred_str))\n",
    "\n",
    "# Obtener y mostrar la matriz de confusión\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(test_df['tipo'], y_pred_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte de Clasificación:\n",
    "\n",
    "Precision: La precisión mide la proporción de predicciones positivas (spam) que fueron correctas. Para la clase 'ham' (no spam), la precisión es del 91%, lo que indica que el 91% de los mensajes clasificados como 'ham' realmente pertenecen a esa categoría. Para la clase 'spam', la precisión es del 83%, lo que significa que el 83% de los mensajes clasificados como 'spam' fueron correctos.\n",
    "\n",
    "Recall: El recall (o sensibilidad) mide la proporción de instancias positivas que fueron correctamente identificadas por el modelo. Para la clase 'ham', el recall es del 83%, lo que indica que el modelo identificó correctamente el 83% de todos los mensajes 'ham' en el conjunto de prueba. Para la clase 'spam', el recall es del 91%, lo que significa que el modelo identificó correctamente el 91% de todos los mensajes 'spam'.\n",
    "\n",
    "F1-score: El F1-score es la media armónica de precision y recall. Es útil cuando las clases están desbalanceadas. En tu caso, ambos F1-scores son del 87%, lo que indica un buen equilibrio entre precision y recall para ambas clases.\n",
    "\n",
    "Support: Es el número de ocurrencias reales de cada clase en el conjunto de prueba.\n",
    "\n",
    "# Matriz de Confusión:\n",
    "\n",
    "La matriz de confusión muestra un resumen visual del rendimiento del modelo:\n",
    "\n",
    "En la fila correspondiente a 'ham':\n",
    "\n",
    "90 mensajes fueron correctamente clasificados como 'ham' (verdaderos negativos).\n",
    "19 mensajes que eran 'ham' fueron incorrectamente clasificados como 'spam' (falsos positivos).\n",
    "En la fila correspondiente a 'spam':\n",
    "\n",
    "9 mensajes que eran 'spam' fueron incorrectamente clasificados como 'ham' (falsos negativos).\n",
    "91 mensajes fueron correctamente clasificados como 'spam' (verdaderos positivos).\n",
    "\n",
    "# Interpretación:\n",
    "\n",
    "El modelo tiene una precisión general del 87% en la clasificación de mensajes ('ham' y 'spam') en el conjunto de datos de prueba.\n",
    "La mayoría de los errores se concentran en la clasificación incorrecta de mensajes 'ham' como 'spam' (falsos positivos).\n",
    "El recall es ligeramente más alto para 'spam' que para 'ham', lo que indica que el modelo tiende a ser más sensible a identificar mensajes 'spam'.\n",
    "En resumen, el modelo muestra un rendimiento sólido en la clasificación de mensajes 'ham' y 'spam', pero podría beneficiarse de ajustes adicionales para reducir los falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación entre los resultads de train y test\n",
    "\n",
    "# Precisión y Recall:\n",
    "\n",
    "En el conjunto de entrenamiento, tanto la precisión como el recall para ambas clases ('ham' y 'spam') son ligeramente más altos en comparación con el conjunto de prueba. Esto sugiere que el modelo generaliza bien, ya que las métricas de evaluación son consistentes entre el entrenamiento y la prueba.\n",
    "\n",
    "La precisión promedio (macro avg) es del 90% en el conjunto de entrenamiento y del 87% en el conjunto de prueba, lo cual indica una ligera caída en el rendimiento en el conjunto de prueba.\n",
    "\n",
    "El recall promedio (macro avg) es del 90% en el conjunto de entrenamiento y del 87% en el conjunto de prueba, mostrando también una ligera disminución en el conjunto de prueba.\n",
    "\n",
    "F1-score:\n",
    "\n",
    "El F1-score promedio (weighted avg) es del 90% en el conjunto de entrenamiento y del 87% en el conjunto de prueba. Esta métrica combina precision y recall, por lo que también refleja una pequeña disminución en el rendimiento en el conjunto de prueba en comparación con el entrenamiento.\n",
    "\n",
    "# Matriz de Confusión:\n",
    "\n",
    "La matriz de confusión muestra patrones de error similares en ambos conjuntos de datos, con más falsos positivos (mensajes 'ham' clasificados incorrectamente como 'spam') que falsos negativos (mensajes 'spam' clasificados incorrectamente como 'ham') en ambos casos.\n",
    "\n",
    "# Conclusión:\n",
    "\n",
    "En general, el modelo muestra una buena capacidad de generalización al conjunto de datos de prueba, con métricas de evaluación sólidas y consistentes con las obtenidas durante el entrenamiento. Sin embargo, hay una ligera disminución en la precisión y recall en el conjunto de prueba, lo cual es común debido a las diferencias naturales entre los datos de entrenamiento y prueba. Esto sugiere que el modelo es robusto pero podría beneficiarse de ajustes adicionales para mejorar su desempeño en la clasificación de mensajes 'ham' y 'spam'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
